###[海量数据处理](http://bit.ly/360T3oX)

看下这个即可。
海量数据处理面试参考:[①](https://www.cnblogs.com/ggzss/archive/2011/10/09/2203308.html)[②](https://www.jianshu.com/p/ac5cad6d64a8)[③](https://www.julyedu.com/question/topic_list/3)
<br>

常识： 1G= 1024 * 1024 * 1024 * 8 = 8589934592 ≈ 80亿

bitmap [①](https://zhuanlan.zhihu.com/p/45637038), [②](http://bit.ly/2rPR086) 用字节数组实现。<br>
byte[512MB] = 512*1024*1024*8的数据大小。<br>
你可以通过val/8定位到在第几个字节上，val%8定位到字节上的第几位。<br>
缺点：对数值大小有限制。 优点：排序，查找，去重。<br>
改进：Bloom filter, K个hash函数映射道指定位，只要其中一位不出现1，那么可以判定val不在这个集合当中。<br>
不管是bloom filter 还是Bitmap 他能处理的数据量还是限制于内存容量的，因此一般的套路是外排序+多路归并，<br>
这也是map reduce的本质。<br>

[10G 文件 2G内存 找中位数](https://zhuanlan.zhihu.com/p/75397875) 
构建1G的MinHeap,找第1G大，第2G大，第3G大，。。。第5G大。或者外排序后，多路归并计数找中位数。<br>

SimHash算法: 用来判定 文档相似性，分词->hash->加权->合并->降维->求汉明距离来判断相似性。<br>

万变不离其宗，分而治之、散列映射+散列统计+堆、快速或者归并排序
先hash分散成小文件，然后hashMap统计频数，然后 minHeap 或者 maxHeap 堆排序<br>
